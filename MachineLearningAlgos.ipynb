{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np #Mathematical tools\n",
    "import matplotlib.pyplot as plt #Plots charts\n",
    "import pandas as pd #Import and manage data sets\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Preprocessing library\n",
    "from sklearn.preprocessing import Imputer\n",
    "# Categorical data encoder library\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "# Splitting the data set into training and testing sets library\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Feature scaling library\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports part 2\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions part 1\n",
    "\n",
    "def best_output(row):\n",
    "    # se o downloadTime é diferente de 100 para T2 e T3, ambos os targets completam o download\n",
    "    if ((row.downloadTimeT2!=100)&(row.downloadTimeT3!=100)):\n",
    "        # o melhor output será aquele para o qual o downloadTime é menor\n",
    "        if (row.downloadTimeT2<=row.downloadTimeT3):\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    \n",
    "    # se o downloadTime é diferente de 100 apenas para um dos targets, só um deles completa o download\n",
    "    elif ((row.downloadTimeT2!=100)|(row.downloadTimeT3!=100)):\n",
    "        # o melhor output será aquele para o qual o downloadTime é diferente de 100\n",
    "        if (row.downloadTimeT2!=100):\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "    # se o downloadTime é igual a 100 para T2 e T3, ambos os targets não completam o download\n",
    "    elif ((row.downloadTimeT2==100)&(row.downloadTimeT3==100)):\n",
    "        # o melhor output será aquele para o qual o rxBytes é maior\n",
    "        if (row.rxBytesT2>=row.rxBytesT3):\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "def download_complete(row, column):\n",
    "    if (row[column]==0):\n",
    "        if(row.downloadTimeT2!=100.0):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        if(row.downloadTimeT3!=100.0):\n",
    "            return 1\n",
    "        else: \n",
    "            return 0\n",
    "\n",
    "        \n",
    "def download_time(row, column):\n",
    "    if ((row[column]==0)&(row.downloadTimeT2<100)):\n",
    "        return row.downloadTimeT2\n",
    "    elif ((row[column]==1)&(row.downloadTimeT3<100)):\n",
    "        return row.downloadTimeT3\n",
    "\n",
    "    \n",
    "def throughput(row, column):\n",
    "    if (row[column]==0):\n",
    "        tp = (row.rxBytesT2/row.downloadTimeT2)*8/1e6\n",
    "        return tp\n",
    "    else:\n",
    "        tp = (row.rxBytesT3/row.downloadTimeT3)*8/1e6\n",
    "        return tp\n",
    "    \n",
    "def optimum_choice(row, column):\n",
    "    if (row[column]==row.best_output):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def a2a4rsrp(row):\n",
    "    if (row.rsrp2>=row.rsrp3):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions part 2\n",
    "def percentageOfErrors(y_real, y_predicted):\n",
    "    p= ((y_predicted != y_real).sum()/ y_real.size)\n",
    "    return p \n",
    "\n",
    "def applyingClassifier (classifier,x_test, x_train, y_test, y_train):\n",
    "    classifier.fit(x_train, y_train)\n",
    "    # Predicting the test set results\n",
    "    y_pred = classifier.predict(x_test)\n",
    "\n",
    "    # Evaluation of the model\n",
    "    # Making the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    p=percentageOfErrors(y_real=y_test, y_predicted=y_pred)\n",
    "    print(p)\n",
    "    return p\n",
    "def applyingAllClassifiers (randomState):\n",
    "    # Splitting test data and train data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2, random_state = randomState)\n",
    "\n",
    "    # Feature scaling (normalizing or stadardization of the scales)\n",
    "    # Helps the conversion of the algorithm\n",
    "    sc_X = StandardScaler()\n",
    "    x_train = sc_X.fit_transform(x_train)\n",
    "    x_test = sc_X.transform(x_test) # There is no need to fit after the training set is fit\n",
    "    # Fitting the KNN to the training set\n",
    "    param_test = {'n_neighbors':[(i) for i in range(1,21)], 'p':[1,2],'weights':['uniform', 'distance']}\n",
    "    classifier=GridSearchCV(estimator=KNeighborsClassifier(metric = 'minkowski', n_jobs=10), param_grid=param_test, scoring='roc_auc')\n",
    "    #classifier = KNeighborsClassifier(n_neighbors = 20, metric = 'minkowski', p = 2)\n",
    "    p_knn=applyingClassifier(classifier=classifier,x_test=x_test, x_train=x_train, y_test=y_test, y_train= y_train)\n",
    "\n",
    "    # Fitting the SVM to the training set\n",
    "    param_test = {'C':[(i) for i in range(1,10)],'kernel':['linear', 'poly', 'rbf', 'sigmoid'],'decision_function_shape':['ovo','ovr'], 'shrinking':[True, False]}\n",
    "    classifier=GridSearchCV(estimator=SVC(random_state=0), param_grid=param_test, cv=10, scoring='roc_auc')\n",
    "    #classifier=SVC(random_state=0)\n",
    "    p_svm=applyingClassifier(classifier=classifier,x_test=x_test,x_train=x_train,y_test=y_test,y_train=y_train)\n",
    "\n",
    "    # Fitting the DT to the training set\n",
    "    classifier = DecisionTreeClassifier(criterion= 'entropy', random_state=0) # the more homogeneous are the groups, the more the entropy falls\n",
    "    p_dt=applyingClassifier(classifier=classifier,x_test=x_test,x_train=x_train,y_test=y_test,y_train=y_train)\n",
    "\n",
    "    # Fitting the RF to the training set\n",
    "    param_test = {'n_estimators':[(i) for i in range(1,50)]}\n",
    "    classifier=GridSearchCV(estimator=RandomForestClassifier(criterion = 'entropy', random_state = 0), param_grid=param_test,cv=10, scoring='roc_auc')\n",
    "    #classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "    p_rf=applyingClassifier(classifier=classifier,x_test=x_test,x_train=x_train,y_test=y_test,y_train=y_train)\n",
    "    p=np.array([p_knn, p_svm, p_dt, p_rf])\n",
    "    return p   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sem shadowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "\n",
    "# importando os datasets\n",
    "t2 = pd.read_csv('resultados/t2_OkumuraHata_Modificado', delimiter='\\t')\n",
    "t3 = pd.read_csv('resultados/t3_OkumuraHata_Modificado', delimiter='\\t')\n",
    "\n",
    "# garantindo que utilizaremos apenas as sementes presentes nos dois datasets\n",
    "t2 = t2[t2.nRun.isin(t3.nRun)]\n",
    "t3 = t3[t3.nRun.isin(t2.nRun)]\n",
    "t2 = t2.reset_index(drop=True)\n",
    "t3 = t3.reset_index(drop=True)\n",
    "\n",
    "# combinando os datasets\n",
    "data = t2\n",
    "data = data.drop(['targetCellId', 'downloadTime', 'rxBytes'], axis=1)\n",
    "data['downloadTimeT2'] = t2.downloadTime\n",
    "data['downloadTimeT3'] = t3.downloadTime\n",
    "data['rxBytesT2'] = t2.rxBytes\n",
    "data['rxBytesT3'] = t3.rxBytes\n",
    "\n",
    "data['best_output'] = data.apply(best_output, axis=1)\n",
    "data.head()\n",
    "\n",
    "# Splitting the data between independent variables and dependent variable\n",
    "y = data['best_output']\n",
    "x = data[['rsrp1','rsrq1','rsrp2','rsrq2','rsrp3','rsrq3','previousrsrp1','previousrsrq1','previousrsrp2','previousrsrq2','previousrsrp3','previousrsrq3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomState 0\n",
      "0.0\n",
      "0.0\n",
      "0.005\n",
      "0.005\n",
      "RandomState 1\n",
      "0.005\n",
      "0.005\n",
      "0.005\n",
      "0.0\n",
      "RandomState 2\n",
      "0.005\n",
      "0.01\n",
      "0.005\n",
      "0.005\n",
      "RandomState 3\n",
      "0.01\n",
      "0.005\n",
      "0.01\n",
      "0.01\n",
      "RandomState 4\n",
      "0.005\n",
      "0.0\n",
      "0.005\n",
      "0.01\n",
      "RandomState 5\n",
      "0.005\n",
      "0.01\n",
      "0.005\n",
      "0.005\n",
      "RandomState 6\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "RandomState 7\n",
      "0.0\n",
      "0.005\n",
      "0.005\n",
      "0.005\n",
      "RandomState 8\n",
      "0.01\n",
      "0.0\n",
      "0.01\n",
      "0.0\n",
      "RandomState 9\n",
      "0.01\n",
      "0.005\n",
      "0.005\n",
      "0.005\n"
     ]
    }
   ],
   "source": [
    "# Applying the classifiers\n",
    "maxRange=10\n",
    "avgP=np.array([0, 0, 0, 0])\n",
    "for (i) in range(0,maxRange):\n",
    "    print(\"RandomState {}\".format(i))\n",
    "    p =applyingAllClassifiers(randomState=i)\n",
    "    avgP=avgP+p\n",
    "avgP=avgP/maxRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.005 ,  0.004 ,  0.0055,  0.0045])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - avgP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Com shadowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "\n",
    "# importando os datasets\n",
    "t2 = pd.read_csv('resultados/t2_OhBuildings_ComShadowing_Modificado', delimiter='\\t')\n",
    "t3 = pd.read_csv('resultados/t3_OhBuildings_ComShadowing_Modificado', delimiter='\\t')\n",
    "\n",
    "# garantindo que utilizaremos apenas as sementes presentes nos dois datasets\n",
    "t2 = t2[t2.nRun.isin(t3.nRun)]\n",
    "t3 = t3[t3.nRun.isin(t2.nRun)]\n",
    "t2 = t2.reset_index(drop=True)\n",
    "t3 = t3.reset_index(drop=True)\n",
    "\n",
    "# combinando os datasets\n",
    "data = t2\n",
    "data = data.drop(['targetCellId', 'downloadTime', 'rxBytes'], axis=1)\n",
    "data['downloadTimeT2'] = t2.downloadTime\n",
    "data['downloadTimeT3'] = t3.downloadTime\n",
    "data['rxBytesT2'] = t2.rxBytes\n",
    "data['rxBytesT3'] = t3.rxBytes\n",
    "\n",
    "data['best_output'] = data.apply(best_output, axis=1)\n",
    "data.head()\n",
    "\n",
    "# Splitting the data between independent variables and dependent variable\n",
    "y = data['best_output']\n",
    "x = data[['rsrp1','rsrq1','rsrp2','rsrq2','rsrp3','rsrq3','previousrsrp1','previousrsrq1','previousrsrp2','previousrsrq2','previousrsrp3','previousrsrq3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomState 0\n",
      "0.378082191781\n",
      "0.312328767123\n",
      "0.369863013699\n",
      "0.347945205479\n",
      "RandomState 1\n",
      "0.33698630137\n",
      "0.284931506849\n",
      "0.372602739726\n",
      "0.361643835616\n",
      "RandomState 2\n",
      "0.372602739726\n",
      "0.27397260274\n",
      "0.356164383562\n",
      "0.364383561644\n",
      "RandomState 3\n",
      "0.394520547945\n",
      "0.339726027397\n",
      "0.347945205479\n",
      "0.342465753425\n",
      "RandomState 4\n",
      "0.383561643836\n",
      "0.295890410959\n",
      "0.378082191781\n",
      "0.369863013699\n",
      "RandomState 5\n",
      "0.356164383562\n",
      "0.284931506849\n",
      "0.369863013699\n",
      "0.350684931507\n",
      "RandomState 6\n",
      "0.372602739726\n",
      "0.284931506849\n",
      "0.369863013699\n",
      "0.375342465753\n",
      "RandomState 7\n",
      "0.369863013699\n",
      "0.320547945205\n",
      "0.334246575342\n",
      "0.328767123288\n",
      "RandomState 8\n",
      "0.361643835616\n",
      "0.298630136986\n",
      "0.356164383562\n",
      "0.416438356164\n",
      "RandomState 9\n",
      "0.372602739726\n",
      "0.33698630137\n",
      "0.380821917808\n",
      "0.361643835616\n"
     ]
    }
   ],
   "source": [
    "# Applying the classifiers\n",
    "maxRange=10\n",
    "avgP=np.array([0, 0, 0, 0])\n",
    "for (i) in range(0,maxRange):\n",
    "    print(\"RandomState {}\".format(i))\n",
    "    p =applyingAllClassifiers(randomState=i)\n",
    "    avgP=avgP+p\n",
    "avgP=avgP/maxRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.63013699,  0.69671233,  0.63643836,  0.63808219])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - avgP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
